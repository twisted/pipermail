<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Twisted-Python] Synchronization techniques
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:twisted-python%40twistedmatrix.com?Subject=Re%3A%20%5BTwisted-Python%5D%20Synchronization%20techniques&In-Reply-To=%3CE0987C5F-E9A2-4AF6-B504-BACB97F637A4%40keystonewood.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=utf-8">
   <LINK REL="Previous"  HREF="047672.html">
   <LINK REL="Next"  HREF="047677.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Twisted-Python] Synchronization techniques</H1>
    <B>Daniel Miller</B> 
    <A HREF="mailto:twisted-python%40twistedmatrix.com?Subject=Re%3A%20%5BTwisted-Python%5D%20Synchronization%20techniques&In-Reply-To=%3CE0987C5F-E9A2-4AF6-B504-BACB97F637A4%40keystonewood.com%3E"
       TITLE="[Twisted-Python] Synchronization techniques">daniel at keystonewood.com
       </A><BR>
    <I>Thu Apr  5 07:53:56 MDT 2007</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="047672.html">[Twisted-Python] Synchronization techniques
</A></li>
        <LI>Next message (by thread): <A HREF="047677.html">[Twisted-Python] Synchronization techniques
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#47674">[ date ]</a>
              <a href="thread.html#47674">[ thread ]</a>
              <a href="subject.html#47674">[ subject ]</a>
              <a href="author.html#47674">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On Apr 5, 2007, at 5:53 AM, <A HREF="https://twistedmatrix.com/cgi-bin/mailman/listinfo/twisted-python">glyph at divmod.com</A> wrote:

&gt;<i> &gt;&gt;I'm afraid that the feature you want doesn't make any sense and  
</I>&gt;<i> is,  in a
</I>&gt;<i> &gt;&gt;broad sense, impossible.
</I>&gt;<i>
</I>&gt;<i> &gt;Maybe it's impossible for you to see things the way I see them   
</I>&gt;<i> because you
</I>&gt;<i> &gt;have become drunk on Twisted Kool-Aide.
</I>&gt;<i>
</I>&gt;<i> You are making it sound like you are bringing a fresh new idea to  
</I>&gt;<i> the discussion here, which I've never heard before and am unwilling  
</I>&gt;<i> to consider because I'm inflexible in my thinking.  That's not  
</I>&gt;<i> what's happening.
</I>
I'm sorry I wrote that...it was inflammatory and did not bring any  
value to the conversation. Please accept my apology.

&gt;<i> &gt;In my specific  case I am running
</I>&gt;<i> &gt;twisted in a single-threaded environment with a  single synchronized
</I>&gt;<i> &gt;resource where each request that needs to access  that resource  
</I>&gt;<i> must gain an
</I>&gt;<i> &gt;exclusive lock before doing anything with  it (a classic locking  
</I>&gt;<i> scenario).
</I>&gt;<i> &gt;This is not &quot;I'm being lazy and I do  not want to learn how to use
</I>&gt;<i> &gt;Deferreds.&quot; Rather, it is a requirement  that is dictated by the  
</I>&gt;<i> system with
</I>&gt;<i> &gt;which I am communicating (it does  not support concurrent access  
</I>&gt;<i> through the
</I>&gt;<i> &gt;API provided by the  vendor). Thus, my code would be much simpler  
</I>&gt;<i> (both to
</I>&gt;<i> &gt;write and  maintain) if I had blockOn(), and it would not have any  
</I>&gt;<i> risk of
</I>&gt;<i> &gt;dead  lock or other such concurrency bugs.
</I>&gt;<i>
</I>&gt;<i> You're confusing two things here.
</I>&gt;<i>
</I>&gt;<i> On the one hand, you want mutual exclusion for an external  
</I>&gt;<i> resource, which blocks.
</I>&gt;<i>
</I>&gt;<i> On the other, you want semantics for implementing that mutual  
</I>&gt;<i> exclusion via blocking in your own process.
</I>&gt;<i>
</I>
The external &quot;blocking&quot; resource is just a shell script that takes  
some time t run. It does not acquire any shared resources that would  
result in dead lock and it will always return (maybe with an error,  
but it will return) unless something terrible happens (e.g. plug is  
pulled on server, fire, etc.).

&gt;<i>
</I>&gt;<i> The former, as you have already demonstrated, can be implemented  
</I>&gt;<i> without the latter.  The question is, would your code actually be  
</I>&gt;<i> simpler to write and to maintain if you had blockOn?  Nothing  
</I>&gt;<i> you've said so far indicates that it would actually be more  
</I>&gt;<i> maintainable, and I've tried (although perhaps failed) to  
</I>&gt;<i> illustrate the high cost of the *apparent* simplicity at the moment  
</I>&gt;<i> of implementation.
</I>
It would be more maintainable because it would look just like normal  
sequential python code:

lock.acquire() # uses blockOn() to acquire a DeferredLock
try:
     process.check_call(['script1.sh']) # uses blockOn(spawnProcess 
(...)) internally
     process.check_call(['script2.sh'])
finally:
     lock.release()

This is very simple and very easy to maintain. It could be written  
with inlineCallbacks fairly easily as well:

yield lock.acquire()
try:
     yield process.check_call(...)
     yeild process.check_call(...)
finally:
     lock.release()

That's pretty nice (so nice I might just rewrite my code that way).  
My complaint is that the code must have knowledge of the twisted  
environment (why else would it yield the result of process.check_call 
()?). I do not really see the conceptual difference between these two  
code blocks except one yields to and one calls into the reactor event  
loop. Is there some other inherent problem with the first example? Of  
course you need to make sure that the code inside the try/finally  
block does not try to acquire the lock again, but that's a basic  
concurrency problem which can even happen in the next example.

Moving on, in a fully deferred world we have this:

def deflock(func, *args, **kw):
     def callback(lock, *args, **kw):
         try:
             result = func(*args, **kw)
         except:
             lock.release()
             raise
         if isinstance(result, Deferred):
             def release(arg, lock):
                 lock.release()
                 return arg
             result.addBoth(release, lock)
         else:
             lock.release()
         return result
     dfr = self.lock.acquire()
     dfr.addCallback(callback, *args, **kw)
     return dfr

def dostuff():
     def deferproc(result, cmd):
         return process.check_call(cmd) # returns a deferred
     dfr = deferproc(None, [&quot;script1.sh&quot;])
     dfr.addCallback(defproc, [&quot;script2.sh&quot;])
     return dfr

dfr = deflock(dostuff)

... you get the picture.

Notice the code to acquire/release the lock--there are three  
different calls to lock.release() in there, and they all must be  
carefully sorted out to make sure that exactly one of them will be  
called in any given scenario--that's hard to maintain.

&gt;<i>
</I>&gt;<i> It strikes me that the process actually making the foreign API call  
</I>&gt;<i> could just block &quot;for real&quot; which would solve the mutual exclusion  
</I>&gt;<i> issue - callers into the PB layer would appear to be getting  
</I>&gt;<i> concurrent access, but responses would be implicitly queued up.
</I>
Right, that would work and that's exactly what subprocess.check_call 
() (the real python built-in version) would do. Unfortunately twisted  
does not work with the subprocess module--spawnProcess() is the only  
alternative I found that actually works and that means I have to use  
a deferred.

&gt;<i>
</I>&gt;<i> Another solution here would be for Twisted to have a nice  
</I>&gt;<i> convenience API for dispatching tasks to a process pool.  Right now  
</I>&gt;<i> setting up a process pool is conceptually easy but mechanically  
</I>&gt;<i> difficult; you have to do a lot of typing and make a lot of  
</I>&gt;<i> irrelevant decisions (AMP or PB or pickle?  stdio or sockets?).
</I>
That sounds nice.

&gt;<i>
</I>&gt;<i> &gt;You might ask why I bother to
</I>&gt;<i> &gt;use Twisted? -- Perspective Broker is the most elegant way I  
</I>&gt;<i> could  find to
</I>&gt;<i> &gt;call remote methods in Python. If it were abstracted from  Twisted  
</I>&gt;<i> to become
</I>&gt;<i> &gt;a fully synchronous library I would use that  instead, but at this  
</I>&gt;<i> point it
</I>&gt;<i> &gt;seems that if I want PB I am stuck with Twisted too.
</I>&gt;<i>
</I>&gt;<i> This is another area where the feature request doesn't quite make  
</I>&gt;<i> sense.  It would be possible to implement something that looked  
</I>&gt;<i> kinda-sorta like PB, which dealt with a single request/response  
</I>&gt;<i> pair over a single socket, in an apparently synchronous and  
</I>&gt;<i> blocking manner.  However, PB itself is a fully symmetrical  
</I>&gt;<i> protocol where the server can send messages to the client at any  
</I>&gt;<i> time, so a full PB implementation is not really possible when any  
</I>&gt;<i> message can be replied to with a &quot;busy, poor implementation doesn't  
</I>&gt;<i> allow me to answer that message in this state&quot; error.
</I>
I understand that PB is fully symmetrical. In my case I am only using  
half (client makes request, server responds). Would it make sense to  
relax the constraints when PB is used in this way?

&gt;<i>
</I>&gt;<i> &gt;Everything I've read about this issue suggests that the twisted   
</I>&gt;<i> developers
</I>&gt;<i> &gt;just don't want to give people what they want because it  would  
</I>&gt;<i> allow them
</I>&gt;<i> &gt;to shoot themselves in the foot (for example, by  using blockOn()  
</I>&gt;<i> in a
</I>&gt;<i> &gt;multi-threaded environment or in inappropriate  places such as the  
</I>&gt;<i> example
</I>&gt;<i> &gt;above). But this is Python and we're  consenting adults. With the  
</I>&gt;<i> proper
</I>&gt;<i> &gt;warnings a feature like this could  make twisted much more  
</I>&gt;<i> palatable for
</I>&gt;<i> &gt;people with large existing  projects that do not wish to rewrite  
</I>&gt;<i> entire
</I>&gt;<i> &gt;sections of code just to  work with deferreds. It would allow  
</I>&gt;<i> people to get
</I>&gt;<i> &gt;the easiest thing  working as quickly as possible, and then go  
</I>&gt;<i> back and
</I>&gt;<i> &gt;write the  optimal deferred implementation later when
</I>&gt;<i> &gt;performance/blocking/etc.  becomes an issue.
</I>&gt;<i>
</I>&gt;<i> I agree that it would be nice to allow programs to get on the  
</I>&gt;<i> Twisted bandwagon slowly, and to integrate more cleanly with  
</I>&gt;<i> foreign concurrency mechanisms like microthreads and database  
</I>&gt;<i> transactions.  This is exactly what Jim Fulton is working on with  
</I>&gt;<i> the multi-reactor stuff for ZEO.  You can't have one reentrant  
</I>&gt;<i> reactor, but you *can*, at least conceptually, have one reactor  
</I>&gt;<i> start another reactor and wait for it to complete a particular  
</I>&gt;<i> operation.  If you'd like to help other projects gradually adapt to  
</I>&gt;<i> Twisted, perhaps you would like to contribute something to ticket  
</I>&gt;<i> #2545.
</I>
This looks very interesting. I'll try to help out with this effort if  
I can find some time.

Thanks for taking time to read my ramblings and understand the  
problems that I am having (even if we don't quite agree on the  
simplest solutions). Your input is valuable, and I am indebted to you  
for providing free support in your spare time.

~ Daniel




</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="047672.html">[Twisted-Python] Synchronization techniques
</A></li>
	<LI>Next message (by thread): <A HREF="047677.html">[Twisted-Python] Synchronization techniques
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#47674">[ date ]</a>
              <a href="thread.html#47674">[ thread ]</a>
              <a href="subject.html#47674">[ subject ]</a>
              <a href="author.html#47674">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://twistedmatrix.com/cgi-bin/mailman/listinfo/twisted-python">More information about the Twisted-Python
mailing list</a><br>
</body></html>
