<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [Twisted-Python] Re: Memory size of Deferreds
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:twisted-python%40twistedmatrix.com?Subject=%5BTwisted-Python%5D%20Re%3A%20Memory%20size%20of%20Deferreds&In-Reply-To=">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="017740.html">
   <LINK REL="Next"  HREF="017742.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Twisted-Python] Re: Memory size of Deferreds</H1>
    <B>Martin Geisler</B> 
    <A HREF="mailto:twisted-python%40twistedmatrix.com?Subject=%5BTwisted-Python%5D%20Re%3A%20Memory%20size%20of%20Deferreds&In-Reply-To="
       TITLE="[Twisted-Python] Re: Memory size of Deferreds">mg at daimi.au.dk
       </A><BR>
    <I>Wed May 21 03:56:30 EDT 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="017740.html">[Twisted-Python] Re: Memory size of Deferreds
</A></li>
        <LI>Next message: <A HREF="017742.html">[Twisted-Python] Re: Memory size of Deferreds
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#17741">[ date ]</a>
              <a href="thread.html#17741">[ thread ]</a>
              <a href="subject.html#17741">[ subject ]</a>
              <a href="author.html#17741">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Micha&#322; Pasternak &lt;<A HREF="http://twistedmatrix.com/cgi-bin/mailman/listinfo/twisted-python">michal.dtz at gmail.com</A>&gt; writes:

&gt;&gt;<i>   def add(x, y):
</I>&gt;&gt;<i>       sum = gatherResults([x, y])
</I>&gt;&gt;<i>       sum.addCallback(lambda results: results[0] + results[1])
</I>&gt;&gt;<i>       return sum
</I>&gt;&gt;<i> 
</I>&gt;&gt;<i> Multiplication is similar, but requires network communication --
</I>&gt;&gt;<i> that is why it returns a Deferred.
</I>&gt;<i>
</I>&gt;<i> I don't think that there's anything wrong with this example in terms
</I>&gt;<i> of being written using Twisted Python.
</I>
Okay, thanks for looking at it!

&gt;&gt;<i> The important point is that as much as possible is done in
</I>&gt;&gt;<i> parallel, that all operations run as soon as their operands are
</I>&gt;&gt;<i> available. Twisted made this extremely easy thanks to the
</I>&gt;&gt;<i> DeferredList and Deferred abstraction.
</I>&gt;<i>
</I>&gt;<i> This is the point where I think, that you answered your question. If
</I>&gt;<i> you do stuff in parallel, you use more Deferreds and more memory.
</I>
Yes, I guess you are right... :-) The design tries to do everything at
once with as much parallism as possible. But since bandwidth is
limited, I guess I could achieve the same throughput by scheduling
things in a slower rate. Maybe using something like this:

  class map_parallel(Deferred):
      def __init__(self, iterable, func, max):
          Deferred.__init__(self)
  
          self.iter = iterable
          self.func = func
          self.running = 0
  
          for _ in range(max):
              self.running += 1
              self.run_next(None)
  
      def run_next(self, arg):
          try:
              e = self.iter.next()
              e.addCallback(self.func)
              e.addCallback(self.run_next)
          except StopIteration:
              # The iterator is exhausted.
              self.running -= 1
              if self.running == 0 and not self.called:
                  # All callbacks have finished.
                  self.callback(None)
          # Pass the argument through unchanged.
          return arg

where map_parallel will map a function over a list of Deferreds, but
it will only run up to max function applications in parallel. I will
experiment with it, and if it works well, then it would be cool to
have a class like this in Twisted.

&gt;<i> I will repeat myself now: I would rather try to find other places to
</I>&gt;<i> optimize VIFF, than reducing memory footprint of Deferred. I don't
</I>&gt;<i> have a CS degree, I'm not a mathematician, but from what you wrote
</I>&gt;<i> it seems that maybe it would be worth to try implementing something
</I>&gt;<i> stack-based (like RPN), than the tree approach you seem to be doing
</I>&gt;<i> now - of course if having a stack is something you can have using
</I>&gt;<i> secure multiparty calculations.
</I>
Thanks for the ideas! You could certainly do what you suggest,
changing the schedule like that is okay from a security point of view.
And if I can delay allocating memory until needed by doing so, then it
will definitely be interesting to try.

-- 
Martin Geisler

VIFF (Virtual Ideal Functionality Framework) brings easy and efficient
SMPC (Secure Multi-Party Computation) to Python. See: <A HREF="http://viff.dk/.">http://viff.dk/.</A>



</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="017740.html">[Twisted-Python] Re: Memory size of Deferreds
</A></li>
	<LI>Next message: <A HREF="017742.html">[Twisted-Python] Re: Memory size of Deferreds
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#17741">[ date ]</a>
              <a href="thread.html#17741">[ thread ]</a>
              <a href="subject.html#17741">[ subject ]</a>
              <a href="author.html#17741">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://twistedmatrix.com/cgi-bin/mailman/listinfo/twisted-python">More information about the Twisted-Python
mailing list</a><br>
</body></html>
