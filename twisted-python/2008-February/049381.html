<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Twisted-Python] DeferredList?
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:twisted-python%40twistedmatrix.com?Subject=Re%3A%20%5BTwisted-Python%5D%20DeferredList%3F&In-Reply-To=%3C24f63c200802261441x69201979r86da43abbf427320%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=utf-8">
   
   
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Twisted-Python] DeferredList?</H1>
    <B>Don Smith</B> 
    <A HREF="mailto:twisted-python%40twistedmatrix.com?Subject=Re%3A%20%5BTwisted-Python%5D%20DeferredList%3F&In-Reply-To=%3C24f63c200802261441x69201979r86da43abbf427320%40mail.gmail.com%3E"
       TITLE="[Twisted-Python] DeferredList?">donwsmith at gmail.com
       </A><BR>
    <I>Tue Feb 26 15:41:56 MST 2008</I>
    <P><UL>
        
        
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#49381">[ date ]</a>
              <a href="thread.html#49381">[ thread ]</a>
              <a href="subject.html#49381">[ subject ]</a>
              <a href="author.html#49381">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Greetings,

I have a problem I hope someone here can assist with. I'm using TwistedSNMP
to query a bunch of SNMP devices asynchronously. The behavior I'm trying to
get is to get is to query all the devices via SNMP, each query returns a
deferred, and when all their callbacks have been fired then I want to stop
the reactor and thereby exit the program. I thought perhaps I could put each
of these SNMP deferreds in a DeferredList and add a callback to the
DeferredList that would stop the reactor but it does not do that. Enclosed
is a code sample. Am I doing something incorrectly, or should I do something
different?

Thanks! -Don

&quot;&quot;&quot;Trivial example to retrieve an OID from a remote Agent&quot;&quot;&quot;
from twisted.internet import reactor
from twistedsnmp import snmpprotocol, agentproxy
from twisted.enterprise import adbapi
from twisted.internet import defer
import os

APPNAME = 'ClearSNMP'
d_results = {} #dictionary to store results
device_name = 'Unknown'

db_conn = {'user':'sa',
            'password':'password',
            'host':'localhost',
            'database':'ClearSNMP'
            }

community_string = 'public'

deferred_list = [] #list to help group the snmp requests

outfile = open('outfile.csv','wb',0)
#add headers to the outfile
outfile.write
(&quot;device_name,link_oid,link_name,link_capacity_oid,link_capacity,traffic_in_oid,traffic_in,traffic_out_oid,traffic_out&quot;)

#create the database connection pool
dbpool = adbapi.ConnectionPool(&quot;pymssql&quot;, user=db_conn['user'],
password=db_conn['password'], host=db_conn['host'],
database=db_conn['database'])


def main( class_handler, proxy, oids ):
    &quot;&quot;&quot;Do a getTable on proxy for OIDs and store in oidStore&quot;&quot;&quot;
    df = proxy.getTable(
        oids, timeout=.25, retryCount=5
    )
    if class_handler == 'tasman':
        df.addCallback( tasmanResults )
    else:
        df.addCallback( results )
    #df.addCallback( exiter )
    df.addErrback( errorReporter, proxy )
    #df.addErrback( exiter )
    return df


def tasmanResults( result ):

    &quot;&quot;&quot;Results 'appear' to be a nested dictionary, but it is really an
object of OIDs. I figured out how to get to the OIDs by
    casting them as a dictionary using the built_in dict() function. Now I
can iterate over all the OIDs.&quot;&quot;&quot;
    #print 'Results:'
    d_table_key = {}
    for table_key in result.keys():
        #get the device name. for some reason i have to do this in a loop as
just saying dict(result[table_key])['.1.3.6.1.2.1.1.5.0'] doesn't work
        for oid in dict(result[table_key]).keys():
            if oid=='.1.3.6.1.2.1.1.5.0':
                device_name=str(dict(result[table_key])[oid])

        d_oid = {}
        for oid in dict(result[table_key]).keys():
            d_oid[str(oid)]=dict(result[table_key])[oid]
        d_table_key[str(table_key)] = d_oid
    d_results[device_name]=d_table_key

    #specify the table oids so we can match them appropriately later
    link_name_table    = &quot;.1.3.6.1.2.1.2.2.1.2&quot;
    link_capacity_table    = &quot;.1.3.6.1.2.1.2.2.1.5&quot;
    traffic_in_table    = &quot;.1.3.6.1.2.1.2.2.1.10&quot;
    traffic_out_table    = &quot;.1.3.6.1.2.1.2.2.1.16&quot;

    # For each link name in the table I need to get the values from the
link_capacity, traffic_in and traffic_out tables and put them in the same
line

    for i in d_results.keys():
        d_row = {} #holds the column values for a row

        #set device_name in Row
        d_row['device_name'] = device_name

        for k in d_results[i][link_name_table]:
            #set link_oid and link_name in Row
            d_row['link_oid'] = k
            d_row['link_name'] =
d_results[i][link_name_table][d_row['link_oid']]

            #lookup the capacity metric for this link_oid
            #create the oid to lookup
            d_row['link_capacity_oid'] =
d_row['link_oid'].replace(link_name_table,link_capacity_table)
            d_row['link_capacity'] =
d_results[i][link_capacity_table][d_row['link_capacity_oid']]

            #lookup the traffic_in metric for this link_oid
            #create the oid to lookup
            d_row['traffic_in_oid'] =
d_row['link_oid'].replace(link_name_table,traffic_in_table)
            d_row['traffic_in'] =
d_results[i][traffic_in_table][d_row['traffic_in_oid']]

            #lookup the traffic_out metric for this link_oid
            #create the oid to lookup
            d_row['traffic_out_oid'] =
d_row['link_oid'].replace(link_name_table,traffic_out_table)
            d_row['traffic_out'] =
d_results[i][traffic_out_table][d_row['traffic_out_oid']]

            #Calculate Utilization - if we can


            #print d_row
            out =
d_row['device_name']+&quot;,&quot;+d_row['link_oid']+&quot;,&quot;+d_row['link_name']+&quot;,&quot;+d_row['link_capacity_oid']+&quot;,&quot;+str(d_row['link_capacity'])+&quot;,&quot;+d_row['traffic_in_oid']+&quot;,&quot;+str(d_row['traffic_in'])+&quot;,&quot;+d_row['traffic_out_oid']+&quot;,&quot;+str(d_row['traffic_out'])+'\r\n'
            #print out
            outfile.write(out)
    return result


def errorReporter( err, proxy ):
    #print 'ERROR', err.getTraceback()
    #log the failed snmp query attempt
    print 'Failed to retrieve SNMP counters from agent:',proxy
    return err

def exiter( value ):

    reactor.stop()
    outfile.close()

    return value


def getNetworkElements():
    return dbpool.runQuery(&quot;select top 10 ip, mkt, dns_name, dns_fqdn from
dns where dns_type='TASMAN'&quot;)

def printResult(l):
    for item in l:
        print &quot;Fetching counters for &quot;+item[2]
        #deferred_list.append(snmpSetup(item[0], 161, 'ctipublic','tasman'))
    ipAddress = item[0]
    portno = 161
    community = community_string
    class_handler = 'tasman'
        print ipAddress,portno
        # choose random port in range 25000 to 30000
        port = snmpprotocol.port()
        targetPort = int(portno)
        proxy = agentproxy.AgentProxy(ipAddress,
                  targetPort,
                  community = community,
                  snmpVersion = 'v1',
                  protocol = port.protocol,
                  )


        d_oids = {'.1.3.6.1.2.1.1':&quot;System Tables&quot;,
            '.1.3.6.1.2.1.2.2.1.2':&quot;Circuit Name&quot;,
            '.1.3.6.1.2.1.2.2.1.5':&quot;Capacity&quot;,
            '.1.3.6.1.2.1.2.2.1.10':&quot;Traffic In&quot;,
            '.1.3.6.1.2.1.2.2.1.16':&quot;Traffic Out&quot;
            }

    &quot;&quot;&quot;Do a getTable on proxy for OIDs and store in oidStore&quot;&quot;&quot;
    df = proxy.getTable(
        d_oids, timeout=.25, retryCount=5
    )
    if class_handler == 'tasman':
        df.addCallback( tasmanResults )
    else:
        df.addCallback( results )
    df.addErrback( errorReporter, proxy )
    deferred_list.append(df)
    return



if __name__ == &quot;__main__&quot;:
    import sys
    #start the log service
    from twisted.python import log
    from twisted.python import logfile
    # rotate every 100000000 bytes
    f = logfile.LogFile(APPNAME+str(os.getpid())+&quot;.log&quot;, &quot;Logs&quot;,
rotateLength=100000000)
    # setup logging to use our new logfile
    #log.startLogging(f)


    g = getNetworkElements().addCallback(printResult)
    dl = defer.DeferredList(deferred_list, 0, 0, 1 )
    print dir(dl)
    dl.addCallback(exiter)

    reactor.run()
-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;/pipermail/twisted-python/attachments/20080226/dcde14a6/attachment.html&gt;
</PRE>
<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	
	
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#49381">[ date ]</a>
              <a href="thread.html#49381">[ thread ]</a>
              <a href="subject.html#49381">[ subject ]</a>
              <a href="author.html#49381">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://twistedmatrix.com/cgi-bin/mailman/listinfo/twisted-python">More information about the Twisted-Python
mailing list</a><br>
</body></html>
