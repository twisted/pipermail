<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Twisted-Python] Twisted in a multicore environment
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:twisted-python%40twistedmatrix.com?Subject=Re%3A%20%5BTwisted-Python%5D%20Twisted%20in%20a%20multicore%20environment&In-Reply-To=%3C4FFC6FB5.7040301%40thieprojects.ch%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=utf-8">
   <LINK REL="Previous"  HREF="058266.html">
   <LINK REL="Next"  HREF="058269.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Twisted-Python] Twisted in a multicore environment</H1>
    <B>Werner Thie</B> 
    <A HREF="mailto:twisted-python%40twistedmatrix.com?Subject=Re%3A%20%5BTwisted-Python%5D%20Twisted%20in%20a%20multicore%20environment&In-Reply-To=%3C4FFC6FB5.7040301%40thieprojects.ch%3E"
       TITLE="[Twisted-Python] Twisted in a multicore environment">werner at thieprojects.ch
       </A><BR>
    <I>Tue Jul 10 12:08:53 MDT 2012</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="058266.html">[Twisted-Python] Twisted in a multicore environment
</A></li>
        <LI>Next message (by thread): <A HREF="058269.html">[Twisted-Python] Twisted in a multicore environment
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#58268">[ date ]</a>
              <a href="thread.html#58268">[ thread ]</a>
              <a href="subject.html#58268">[ subject ]</a>
              <a href="author.html#58268">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On 7/10/12 6:17 AM, Laurens Van Houtven wrote:
&gt;<i> FWIW,  I have used Ampoule to great effect, but as JP points out it's hardly the only option. You're bound to end up with some measure of multiprocessing. Bear in mind that not all workloads are well-suited for this kind of problem! Always measure before deciding to make your codebase that much more complicated :)
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> cheers
</I>&gt;<i> lvh
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> On 10 Jul 2012, at 18:03, <A HREF="https://twistedmatrix.com/cgi-bin/mailman/listinfo/twisted-python">exarkun at twistedmatrix.com</A> wrote:
</I>&gt;<i>
</I>&gt;&gt;<i> On 03:14 pm, <A HREF="https://twistedmatrix.com/cgi-bin/mailman/listinfo/twisted-python">augustocaringi at gmail.com</A> wrote:
</I>&gt;&gt;&gt;<i> Hi,
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>    I'm researching the best way to implement/use a Twisted-based
</I>&gt;&gt;&gt;<i> server in a multicore environment...
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>    There is the Ampoule project, that I realize is considered the
</I>&gt;&gt;&gt;<i> best way to do that. Right?
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> It's a way.  &quot;Best&quot; depends on the details and goals of the project.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Here's a stackoverflow question/answer on basically the same topic.  In
</I>&gt;&gt;<i> particular, it specifically answers the question of a listening port
</I>&gt;&gt;<i> shared between multiple processes and gives examples of how to do this:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>   <A HREF="http://bit.ly/MiCHtQ">http://bit.ly/MiCHtQ</A>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Jean-Paul
</I>&gt;&gt;&gt;<i>    I'm also reading about the internals of Nginx HTTP server. This
</I>&gt;&gt;&gt;<i> server utilizes the same reactor pattern of Twisted (epoll based)...
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>    &quot;What resulted is a modular, event-driven, asynchronous,
</I>&gt;&gt;&gt;<i> single-threaded, non-blocking architecture which became the foundation
</I>&gt;&gt;&gt;<i> of nginx code.&quot; <A HREF="http://www.aosabook.org/en/nginx.html">http://www.aosabook.org/en/nginx.html</A>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>    But to maximize the use of processors in a multicore environment,
</I>&gt;&gt;&gt;<i> Nginx do this:
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>    &quot;nginx doesn't spawn a process or thread for every connection.
</I>&gt;&gt;&gt;<i> Instead, worker processes accept new requests from a shared &quot;listen&quot;
</I>&gt;&gt;&gt;<i> socket and execute a highly efficient run-loop inside each worker to
</I>&gt;&gt;&gt;<i> process thousands of connections per worker&quot;
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>    My question: There is something similar in Twisted? Or do you
</I>&gt;&gt;&gt;<i> think that is easy to implement something like that?
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>    Thanks!
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> --
</I>&gt;&gt;&gt;<i> Augusto Mecking Caringi
</I>We observed really great scaling on multi cores with moving the 
application part either to ampoule for PDF production or in the other 
case I wrote an implementation of self regulating process pool based on 
spread, leaving only the serving to twisted in both cases.

With handing work out to other processes you get another benefit which 
is isolation of python, which is the only way to use a package, like 
reportlab which survives no sort of reentrancy, for a webservice.

Werner


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="058266.html">[Twisted-Python] Twisted in a multicore environment
</A></li>
	<LI>Next message (by thread): <A HREF="058269.html">[Twisted-Python] Twisted in a multicore environment
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#58268">[ date ]</a>
              <a href="thread.html#58268">[ thread ]</a>
              <a href="subject.html#58268">[ subject ]</a>
              <a href="author.html#58268">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://twistedmatrix.com/cgi-bin/mailman/listinfo/twisted-python">More information about the Twisted-Python
mailing list</a><br>
</body></html>
