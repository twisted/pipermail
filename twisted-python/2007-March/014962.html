<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [Twisted-Python] Need some pointers for writing asynchronous code	for Twisted app
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:twisted-python%40twistedmatrix.com?Subject=%5BTwisted-Python%5D%20Need%20some%20pointers%20for%20writing%20asynchronous%20code%0A%09for%20Twisted%20app&In-Reply-To=89d8b1b00703091534s741352dcq39c75e1672015741%40mail.gmail.com">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="014961.html">
   <LINK REL="Next"  HREF="014963.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Twisted-Python] Need some pointers for writing asynchronous code	for Twisted app</H1>
    <B>Andrew Bennetts</B> 
    <A HREF="mailto:twisted-python%40twistedmatrix.com?Subject=%5BTwisted-Python%5D%20Need%20some%20pointers%20for%20writing%20asynchronous%20code%0A%09for%20Twisted%20app&In-Reply-To=89d8b1b00703091534s741352dcq39c75e1672015741%40mail.gmail.com"
       TITLE="[Twisted-Python] Need some pointers for writing asynchronous code	for Twisted app">andrew-twisted at puzzling.org
       </A><BR>
    <I>Fri Mar  9 20:02:30 EST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="014961.html">[Twisted-Python] Need some pointers for writing asynchronous code	for Twisted app
</A></li>
        <LI>Next message: <A HREF="014963.html">[Twisted-Python] Need some pointers for writing asynchronous code	for Twisted app
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#14962">[ date ]</a>
              <a href="thread.html#14962">[ thread ]</a>
              <a href="subject.html#14962">[ subject ]</a>
              <a href="author.html#14962">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Brian Costlow wrote:
[...]
&gt;<i> 
</I>&gt;<i> So the easy way out, it seems to me, would be to make the LineRecever callback
</I>&gt;<i> build the ElementTree as I get it. Then wrap minimally modfied versions of the
</I>&gt;<i> code that processes the ElementTree to the dict, and the dict to the database,
</I>&gt;<i> in a callInThread or deferToThread call. Which is a lot of use of the thread
</I>&gt;<i> pool, which seems to violate the idea of a low-overhead asynchronous event
</I>&gt;<i> loop.
</I>
Most databases don't really give you any choice but to use threads.
twisted.enterprise.adbapi helps a little.  Compared to the time it takes for the
database to do its stuff, I doubt you'll notice the thread overhead.

&gt;<i> So is there a better way? For example, if I have a callback chain, when the
</I>&gt;<i> first one fires, do they all fire in sequence as the prior callback returns, or
</I>&gt;<i> does the chain yield to other events. If it does, I could potentially break the
</I>&gt;<i> code into smaller chunks, say so each one processed enough tree data to
</I>&gt;<i> generate 1 dict entry, and add the chunks as a callback chain on the
</I>&gt;<i> connectionLost?
</I>
Deferreds are completely independent of the reactor (i.e. event loop).  They
don't any magical yielding to the event loop or anything like that.  Deferreds
simply manage the chain of callbacks, and arrange for them to be called as soon
as the the data they're waiting on is there.

&gt;<i> Note: None of this code is tested, I'm just trying to get the basic logic
</I>&gt;<i> worked out.
</I>&gt;<i> 
</I>&gt;<i> Something like this?
</I>&gt;<i> 
</I>&gt;<i> def connectionLost(self):
</I>&gt;<i>     d = defer.Deferrred()
</I>&gt;<i>     d.addCallback(chunkOne)
</I>&gt;<i>     d.addCallback(chunkTwo)
</I>&gt;<i>     d.addCallback(chunkThree)
</I>&gt;<i>     d.addCallback(chunkN...)
</I>&gt;<i>     d.addCallback(finish)
</I>&gt;<i>     d.callback(self.myElementTree)
</I>&gt;<i> 
</I>&gt;<i> If I have a bunch of connections that close as simultaneously as the
</I>&gt;<i> implementation allows, does that sequence all fire first for one closing
</I>&gt;<i> connection, then the next, and so on? Or do they intermix?
</I>
They will all fire immediately.  It's just like doing:

    result = chunkOne(self.myElementTree)
    result = chunkTwo(result)
    result = chunkTwo(result)
    result = chunkThree(result)
    result = chunkN(result)
    ...
    finish(result)

i.e. synchronous.

&gt;<i> Or do I need to set up a chain of deferreds with explicit scheduling?
</I>&gt;<i> 
</I>&gt;<i> Something like:
</I>&gt;<i> 
</I>&gt;<i> def connectionLost(self):
</I>&gt;<i>    self.myDict = {}
</I>&gt;<i>    finish()
</I>&gt;<i> 
</I>&gt;<i> def finish(self)
</I>&gt;<i>    d = defer.Deferred
</I>&gt;<i>    def realFinish(d):
</I>&gt;<i>          do stuff to clean up
</I>&gt;<i>    d.addCallback(ChunkThree)
</I>&gt;<i>    d.addCallback(realFinish)
</I>&gt;<i>    reactor.callLater(0, d.callback, None)
</I>&gt;<i> 
</I>&gt;<i> def chunkThree()
</I>&gt;<i>     d = defer.Deferred
</I>&gt;<i>     def realChunkThree(self.MyElementTree, self.myDict):
</I>&gt;<i>          do stuff to process one dict key
</I>&gt;<i>     d.addCallback(ChunkTwo)
</I>&gt;<i>     d.addCallback(realChunkThree)
</I>&gt;<i>     reactor.callLater(0, d.callback, None)
</I>&gt;<i>     return d
</I>
This is an awkward way to arrange it, but this would let the reactor do work
between the chunks, yes.

&gt;<i> The above doesn't really seem much different than the first, it's just that we
</I>&gt;<i> schedule the calls explicitly, and pass data around in multiple deferreds. 
</I>&gt;<i> 
</I>&gt;<i> The  last thing I though about doing was something like this:
</I>&gt;<i> 
</I>&gt;<i> def connectionLost(self):
</I>&gt;<i>     myDict = {}
</I>&gt;<i>     d.defer.Deferred()
</I>&gt;<i>     d.addCallback(finish)
</I>&gt;<i>     myIterObj = self.myElementTree.getIterator()
</I>&gt;<i>     def processChunk():
</I>&gt;<i>         try:
</I>&gt;<i>             foo = myIterObj.next()
</I>&gt;<i>             do stuff with foo to process element to dict entry
</I>&gt;<i>         except StopIteration:
</I>&gt;<i>             d.callback(None)
</I>&gt;<i>         except:
</I>&gt;<i>             error handling stuff
</I>&gt;<i>         else
</I>&gt;<i>             reactor.callLater(0, processChunk)
</I>&gt;<i>     return d
</I>
This approach can work a little better, yeah.

Note that returning a Deferred from connectionLost doesn't do anything.  What do
you want to wait on the deferred (i.e. what in your code is waiting on this
result)?  As far as I can tell, nothing.  If so, you probably don't want a
Deferred at all.

<A HREF="http://twistedmatrix.com/projects/core/documentation/examples/longex.py">http://twistedmatrix.com/projects/core/documentation/examples/longex.py</A> and
<A HREF="http://twistedmatrix.com/projects/core/documentation/examples/longex2.py">http://twistedmatrix.com/projects/core/documentation/examples/longex2.py</A>

Have some basic examples of this sort of stuff.

There's also the &quot;cooperator&quot; module in
<A HREF="http://divmod.org/trac/wiki/DivmodEpsilon,">http://divmod.org/trac/wiki/DivmodEpsilon,</A> but it's totally lacking in
documentation.  So who knows if it's really appropriate for this, or if you'll
be able to figure out how to use it.

&gt;<i> Except I found some really similar code in an old thread, where Bob Ippolito
</I>&gt;<i> says, 'just use flow instead'
</I>&gt;<i> <A HREF="http://twistedmatrix.com/pipermail/twisted-python/2003-July/005013.html">http://twistedmatrix.com/pipermail/twisted-python/2003-July/005013.html</A>
</I>&gt;<i> 
</I>&gt;<i> But the current flow doc says: Don't use flow, write asynchronous code.
</I>
In this case, twisted.internet.defer.inlineCallbacks could probably be used
instead of flow:

     @inlineCallbacks
     def doChunks():
         for chunk in chunks:
             # do the next chunk
             chunk()
             # yield to the event loop
             d = Deferred()
             reactor.callLater(0, d.callback, None)
             yield d

(The deferLater function in <A HREF="http://twistedmatrix.com/trac/ticket/1875">http://twistedmatrix.com/trac/ticket/1875</A> would make
this even shorter.)

Finally, are you sure you really need to chunk this processing at all?
ElementTree is pretty fast; it's entirely possible that breaking it into chunks
and going in-and-out of the event loop repeatedly will hurt your performance
more than just doing it all at once.  It might be a good idea to check if you
actually have a real performance problem (rather than just a theoretical one)
before you worry about solving it.

Similarly, consider just putting the computationally expensive stuff in a
deferToThread call and letting your OS worry about scheduling it.  If the
processing doesn't need to interact much with the event-driven code, then this
can be a good option.

-Andrew.



</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="014961.html">[Twisted-Python] Need some pointers for writing asynchronous code	for Twisted app
</A></li>
	<LI>Next message: <A HREF="014963.html">[Twisted-Python] Need some pointers for writing asynchronous code	for Twisted app
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#14962">[ date ]</a>
              <a href="thread.html#14962">[ thread ]</a>
              <a href="subject.html#14962">[ subject ]</a>
              <a href="author.html#14962">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://twistedmatrix.com/cgi-bin/mailman/listinfo/twisted-python">More information about the Twisted-Python
mailing list</a><br>
</body></html>
